{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMxezgXLL5DrdFzP3F3cqoF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vitorhugo653/Projetoalura/blob/main/BPL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Suprimir saidas\n",
        "%%capture\n",
        "!pip install PyPDF2\n",
        "!pip install sentence_transformers\n",
        "!pip install -U -q google.generativeai\n",
        "\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "import PyPDF2\n",
        "import requests\n",
        "import google.generativeai as genai"
      ],
      "metadata": {
        "id": "2kRn-g09LQpV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configurar API do Google Generative AI (substitua pela sua chave real)\n",
        "import os\n",
        "from google.colab import userdata\n",
        "api_key = userdata.get('secret_key')\n",
        "os.environ[\"GOOGLE_API_KEY\"] = api_key\n",
        "genai.configure()"
      ],
      "metadata": {
        "id": "bgIP6lm_LZUR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregue um modelo de embeddings pré-treinado\n",
        "model = SentenceTransformer('all-mpnet-base-v2')"
      ],
      "metadata": {
        "id": "yYvNxletLcqr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Função para extrair texto de um PDF a partir de uma URL\n",
        "def extract_text_from_pdf_url(pdf_url):\n",
        "  response = requests.get(pdf_url)\n",
        "  with open('temp.pdf', 'wb') as f:\n",
        "    f.write(response.content)\n",
        "  with open('temp.pdf', 'rb') as f:\n",
        "    pdf_reader = PyPDF2.PdfReader(f)\n",
        "    text = \"\"\n",
        "    for page_num in range(len(pdf_reader.pages)):\n",
        "      page = pdf_reader.pages[page_num]\n",
        "      text += page.extract_text()\n",
        "  return text"
      ],
      "metadata": {
        "id": "oxyglPvSLgwZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# URLs dos seus PDFs\n",
        "pdf_urls = [\n",
        "    'https://antigo.anvisa.gov.br/documents/10181/6278771/RDC_512_2021_.pdf/5650229b-218e-467a-83dd-e292581c20fe',\n",
        "    'https://www.exactusmetrologia.com.br/sites/default/files/3-nbr_iso_iec_17025-2017_versao_exclusiva_treinamento.pdf'\n",
        "]"
      ],
      "metadata": {
        "id": "jKuzb06KLmjm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extraia o texto dos PDFs\n",
        "documents = []\n",
        "for url in pdf_urls:\n",
        "    documents.append({\n",
        "        'url': url,\n",
        "        'content': extract_text_from_pdf_url(url)\n",
        "    })"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3aM7Tc_Lrzq",
        "outputId": "cf6b0e79-e3ca-4842-cdf6-ac97ea8824bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:PyPDF2._reader:Overwriting cache for 0 905\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Gere embeddings para cada documento\n",
        "for document in documents:\n",
        "    document['embedding'] = model.encode(document['content'])\n",
        "\n",
        "# Função para buscar documentos\n",
        "def search_documents(query):\n",
        "    query_embedding = model.encode(query)\n",
        "    results = []\n",
        "    for document in documents:\n",
        "        similarity = util.cos_sim(query_embedding, document['embedding'])\n",
        "        results.append({\n",
        "            'url': document['url'],\n",
        "            'content': document['content'],\n",
        "            'similarity': similarity.item()\n",
        "        })\n",
        "    return sorted(results, key=lambda x: x['similarity'], reverse=True)"
      ],
      "metadata": {
        "id": "IWoZ53M9LuXU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Função para formatar em Markdown\n",
        "def to_markdown(text):\n",
        "  text = text.replace('•', '  *')\n",
        "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"
      ],
      "metadata": {
        "id": "fNBEfCStU4Gd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Função do chatbot\n",
        "def chatbot():\n",
        "    chat_history = []  # Armazena o histórico da conversa\n",
        "\n",
        "    while True:\n",
        "        query = input(\"\\nFaça sua pergunta:\\n\")\n",
        "        if query.lower() == 'sair':\n",
        "            break\n",
        "\n",
        "        results = search_documents(query)\n",
        "        if results:\n",
        "            best_match = results[0]\n",
        "\n",
        "            # Reformule a resposta\n",
        "            prompt = f\"Rescreva esse texto de uma maneira descontraída: {best_match['content']}\"\n",
        "            model_2 = genai.GenerativeModel(\"gemini-pro\")\n",
        "            response = model_2.generate_content(prompt)\n",
        "\n",
        "            # Adiciona a pergunta e a resposta ao histórico\n",
        "            chat_history.append({'role': 'Usuário', 'content': query})\n",
        "            chat_history.append({'role': 'Chatbot', 'content': response.text})\n",
        "\n",
        "            # Imprime o histórico formatado\n",
        "            for message in chat_history:\n",
        "                display(to_markdown(f'**{message[\"role\"]}**: {message[\"content\"]}'))\n",
        "                print('-'*100)\n",
        "\n",
        "        else:\n",
        "            print(\"Nenhum resultado encontrado.\")\n",
        "\n",
        "# Inicie o chatbot\n",
        "chatbot()"
      ],
      "metadata": {
        "id": "XKFU-YQ5wJfC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}